---
layout: page
title: Research
desc: Side projects are fun.
permalink: /research/
---

<p>I work primarily on <strong>Reinforcement Learning</strong> and <strong>Design of Experiments</strong>, although I am broadly interested in <strong>Uncertainty in Machine Learning</strong>. Before graduate school I did some work on <strong>Probabilistic Modelling</strong> for transportation systems. See my <a href="https://scholar.google.com/citations?user=dknW9_sAAAAJ&hl=en&oi=ao">Google Scholar</a> for the most up to date list of academic publications.</p>

<div class="projects">
  <div class="grid no-gutters">

    
    
    
    <div class="unit whole">
      <h4 class="project-title"><a href="" style="padding-bottom: 0rem;">Efficient Bayesian Optimal Experimental Design with Graph Neural Networks</a></h4>    
      <div class="unit one-fifth">
        <div class="project">
          <img src="{{ site.baseurl }}/assets/img/gnn_boed.png" alt="Conor Igoe" width=100% />
        </div>
      </div>

      <div class="unit four-fifths">
        <h6><em>Conor Igoe</em>, Jeff Schneider</h6>
        <div class="project">
          <p>We propose using Graph Neural Networks with DRL for Bayesian Optimal Experimental Design. We illustrate how "Belief Explosion" is a significant bottleneck in BOED DRL training, requiring well-chosen inductive biases to reduce offline computation. Our approach improves sample efficiency by multiple orders of magnitude compared to naive parameterizations by leveraging permutation equivariance.
          <br>
              <strong>2023.</strong>
          </p>
        </div>
      </div>
    </div>           
    
    
    
    
    
    <div class="unit whole">
      <h4 class="project-title"><a href="https://proceedings.mlr.press/v202/malik23a/malik23a.pdf" style="padding-bottom: 0rem;">Weighted Tallying Bandits: Overcoming Intractability via Repeated Exposure Optimality</a></h4>    
      <div class="unit one-fifth">
        <div class="project">
          <img src="{{ site.baseurl }}/assets/img/wtb.png" alt="Conor Igoe" width=100% />
        </div>
      </div>

      <div class="unit four-fifths">
        <h6>Dhruv Malik, <em>Conor Igoe</em>, Yuanzhi Li, Aarti Singh</h6>
        <div class="project">
          <p>We introduce the Weighted Tallying Bandit (WTB) problem setting, which generalizes previous online learning settings to capture the decay of human memory with time. We motivate the Repeated Exposure Optimality (REO) property and study the minimisation of Complete Policy Regret in WTB instances satisfying REO. We provide theory and simulation results showing how the Successive Elimination algorithm is well-suited for this class of problems.
          <br>
              <strong>ICML 2023.</strong>                 
          </p>
        </div>
      </div>
    </div>           
    
    
    
    
    
    
    
    <div class="unit whole">
      <h4 class="project-title"><a href="https://youtu.be/ElPDD9NYhR0" style="padding-bottom: 0rem;">Multi-Alpha Soft Actor-Critic: Overcoming Stochastic Biases in Maximum Entropy Reinforcement Learning</a></h4>    
      <div class="unit one-fifth">
        <div class="project">
          <img src="{{ site.baseurl }}/assets/img/mas.png" alt="Conor Igoe" width=100% />
        </div>
      </div>

      <div class="unit four-fifths">
        <h6><em>Conor Igoe</em>, Swapnil Pande, Siddarth Venkatraman, Jeff Schneider</h6>
        <div class="project">
          <p>Robotic control requires intelligent decision-making in complex scenarios. Soft Actor-Critic is a popular DRL algorithm but its entropy-based learning objective introduces bias. We show how naively reducing the bias leads to slow or unstable learning. We propose Multi-Alpha Soft Actor-Critic which treats the entropy coefficient as a random variable, overcoming the bias and maintaining stability and efficiency in robotic control tasks.
          <br>
              <strong>ICRA 2023.</strong>                
          </p>
        </div>
      </div>
    </div>       

    
    
    <div class="unit whole">
      <h4 class="project-title"><a href="https://arxiv.org/abs/2205.10439" style="padding-bottom: 0rem;">How Useful are Gradients for OOD Detection Really?</a></h4>
      <div class="unit one-fifth">
        <div class="project">
          <img src="{{ site.baseurl }}/assets/img/ood.png" alt="Conor Igoe" width=200/>
        </div>
      </div>

      <div class="unit four-fifths">
        <h6><em>Conor Igoe</em>, Youngseog Chung, Ian Char, Jeff Schneider</h6>        
        <div class="project">
          <p>Detecting when a model is unable to make accurate predictions is crucial for real-world applications. Previous methods utilizing test-time gradients for OOD detection have shown competitive performance, but there are misconceptions about the necessity of gradients. In this work, we provide an in-depth analysis of test-time gradients and propose a general, non-gradient-based method of OOD detection.
          <br>
           <strong>arXiv 2022.</strong>                          
          </p>            
        </div>
      </div>
    </div>        
  
   
       
    
    
    
    
    
    <div class="unit whole">
      <h4 class="project-title"><a href="https://youtu.be/vulStCNUiaI" style="padding-bottom: 0rem;">Multi-Agent Active Search: A Reinforcement Learning Approach</a></h4>    
      <div class="unit one-fifth">
        <div class="project">
          <img src="{{ site.baseurl }}/assets/img/darpa_gif.gif" alt="Conor Igoe" width=100% />
        </div>
      </div>

      <div class="unit four-fifths">
        <h6><em>Conor Igoe</em>, Ramina Ghods, Jeff Schneider</h6>                
        <div class="project">
          <p>Multi-Agent Active Search (MAAS) is an active learning problem with the objective of locating sparse targets in an unknown environment by actively making data-collection decisions. We argue that Deep RL is a particularly strong choice for active search tasks from decision-theoretic and computational perspectives.          
            <br>
            <strong>ICRA 2022.</strong>                          
          </p>     
        </div>
      </div>
    </div>      
    
    
    <div class="unit whole">
      <h4 class="project-title"><a href="https://www.ri.cmu.edu/wp-content/uploads/2020/03/Generating_Highly_Predictive_Probabilistic_Models_Of_Task_Durations__Final_Version.pdf" style="padding-bottom: 0rem;">Hierarchical Bayesian Framework For Bus Dwell Time Prediction</a></h4>
      <div class="unit one-fifth">
        <div class="project">
          <img src="{{ site.baseurl }}/assets/img/bus.png" alt="Conor Igoe" width=200/>
        </div>
      </div>

      <div class="unit four-fifths">
        <h6>Isaac K. Isukapati, <em>Conor Igoe</em>, Eli Bronstein, Viraj Parimi, Stephen F. Smith</h6>
        <div class="project">
          <p>We develop Bayesian models for predicting bus arrival times at signalized intersections. Our approach accounts for uncertainty in bus dwell time, which is crucial for accurate predictions. We use minimal data and provide a rich description of confidence for decision-making. Our results show that our approach yields significantly more accurate predictions than standard regression and deep learning techniques, making it useful for real-time traffic signal optimization.
          <br>
          <strong>IEEE ITS 2020.</strong>
          </p>
        </div>
      </div>
    </div>        
    
    
     
    
    
    
    <div class="unit whole">
      <h4 class="project-title"><a href="https://apps.dtic.mil/sti/pdfs/AD1078688.pdf" style="padding-bottom: 0rem;">Multi-armed bandits with delayed and aggregated rewards</a></h4>    
      <div class="unit one-fifth">
        <div class="project">
          <img src="{{ site.baseurl }}/assets/img/bandit.png" alt="Conor Igoe" width=100% />
        </div>
      </div>

      <div class="unit four-fifths">
        <h6>Jacob Tyo, Ojash Neopane, Jonathon Byrd, Chirag Gupta, <em>Conor Igoe</em></h6>
        <div class="project">
          <p>We study the multi-armed bandit problem under delayed feedback. Recent algorithms have desirable regret bounds in the delayed-feedback setting but require strict prior knowledge of expected delays. We study the regret of such delay-resilient algorithms under milder assumptions. We empirically investigate known theoretical performance bounds and attempt to improve on a recently proposed algorithm by making looser assumptions on prior delay knowledge.
          <br>    
          <strong>CCDC ARL 2019.</strong>
          </p>
        </div>
      </div>
    </div>       
    
    
    
    
    
  </div><!-- grid -->
</div>
